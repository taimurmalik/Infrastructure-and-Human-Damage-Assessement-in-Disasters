{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb9041c5-9746-4a93-b233-13383f6f7c9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4379 images belonging to 8 classes.\n",
      "Found 1713 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3458s\u001b[0m 13s/step - accuracy: 0.8702 - loss: 0.4771 - val_accuracy: 0.8745 - val_loss: 0.3666 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3453s\u001b[0m 13s/step - accuracy: 0.9306 - loss: 0.1950 - val_accuracy: 0.8646 - val_loss: 0.3999 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3456s\u001b[0m 13s/step - accuracy: 0.9745 - loss: 0.0813 - val_accuracy: 0.8466 - val_loss: 0.6725 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3458s\u001b[0m 13s/step - accuracy: 0.9951 - loss: 0.0172 - val_accuracy: 0.8459 - val_loss: 0.8127 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3467s\u001b[0m 13s/step - accuracy: 0.9972 - loss: 0.0124 - val_accuracy: 0.8506 - val_loss: 0.8003 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3451s\u001b[0m 13s/step - accuracy: 0.9996 - loss: 0.0029 - val_accuracy: 0.8581 - val_loss: 0.8861 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When passing a Python generator to a Keras model, the generator must return a tuple, either (input,) or (inputs, targets) or (inputs, targets, sample_weights). Received: {'text_input': array([[   0,    0,    0, ..., 6226,    2,   91],\n       [   0,    0,    0, ..., 4129,   31, 1280],\n       [   0,    0,    0, ..., 2337,  362,   22],\n       ...,\n       [   0,    0,    0, ..., 2058, 1142,  312],\n       [   0,    0,    0, ..., 1936,    6,   42],\n       [   0,    0,    0, ...,    2,    1, 3687]]), 'image_input': array([[[[0.7176471 , 0.6509804 , 0.72156864],\n         [0.7176471 , 0.6509804 , 0.72156864],\n         [0.7176471 , 0.6509804 , 0.7137255 ],\n         ...,\n         [0.4039216 , 0.20784315, 0.07843138],\n         [0.3921569 , 0.19607845, 0.06666667],\n         [0.37647063, 0.1764706 , 0.05490196]],\n\n        [[0.69803923, 0.6313726 , 0.7019608 ],\n         [0.7019608 , 0.63529414, 0.7058824 ],\n         [0.7019608 , 0.63529414, 0.69803923],\n         ...,\n         [0.4039216 , 0.20784315, 0.07843138],\n         [0.4156863 , 0.21960786, 0.09019608],\n         [0.35686275, 0.15686275, 0.03529412]],\n\n        [[0.67058825, 0.6156863 , 0.68235296],\n         [0.6745098 , 0.61960787, 0.6862745 ],\n         [0.6784314 , 0.62352943, 0.68235296],\n         ...,\n         [0.3921569 , 0.19607845, 0.06666667],\n         [0.43529415, 0.2392157 , 0.10980393],\n         [0.31764707, 0.11764707, 0.        ]],\n\n        ...,\n\n        [[0.07843138, 0.09019608, 0.10980393],\n         [0.13725491, 0.14901961, 0.16862746],\n         [0.20392159, 0.20784315, 0.227451  ],\n         ...,\n         [0.19607845, 0.05882353, 0.0509804 ],\n         [0.12941177, 0.00392157, 0.01568628],\n         [0.15294118, 0.03137255, 0.05490196]],\n\n        [[0.1137255 , 0.12941177, 0.14117648],\n         [0.16470589, 0.18039216, 0.19215688],\n         [0.21960786, 0.23137257, 0.2509804 ],\n         ...,\n         [0.20000002, 0.0627451 , 0.05490196],\n         [0.1254902 , 0.        , 0.01176471],\n         [0.16470589, 0.04313726, 0.0627451 ]],\n\n        [[0.15294118, 0.17254902, 0.18431373],\n         [0.20392159, 0.21960786, 0.23137257],\n         [0.24313727, 0.25882354, 0.27058825],\n         ...,\n         [0.20784315, 0.07058824, 0.0627451 ],\n         [0.1254902 , 0.        , 0.00392157],\n         [0.1764706 , 0.05490196, 0.07450981]]],\n\n\n       [[[0.5882353 , 0.59607846, 0.64705884],\n         [0.57254905, 0.58431375, 0.6431373 ],\n         [0.5411765 , 0.5647059 , 0.627451  ],\n         ...,\n         [0.61960787, 0.63529414, 0.68235296],\n         [0.7019608 , 0.7176471 , 0.76470596],\n         [0.6862745 , 0.7019608 , 0.7490196 ]],\n\n        [[0.5686275 , 0.5803922 , 0.6392157 ],\n         [0.56078434, 0.57254905, 0.6313726 ],\n         [0.5372549 , 0.56078434, 0.62352943],\n         ...,\n         [0.7019608 , 0.70980394, 0.7568628 ],\n         [0.72156864, 0.7372549 , 0.7803922 ],\n         [0.6627451 , 0.6784314 , 0.72156864]],\n\n        [[0.57254905, 0.58431375, 0.6431373 ],\n         [0.5764706 , 0.5882353 , 0.64705884],\n         [0.56078434, 0.58431375, 0.64705884],\n         ...,\n         [0.64705884, 0.65882355, 0.6862745 ],\n         [0.7254902 , 0.7372549 , 0.76470596],\n         [0.7254902 , 0.74509805, 0.7686275 ]],\n\n        ...,\n\n        [[0.36078432, 0.39607847, 0.454902  ],\n         [0.34901962, 0.38431376, 0.4431373 ],\n         [0.33333334, 0.36862746, 0.427451  ],\n         ...,\n         [0.07843138, 0.15686275, 0.2627451 ],\n         [0.10588236, 0.18823531, 0.29411766],\n         [0.13333334, 0.227451  , 0.32941177]],\n\n        [[0.3254902 , 0.36078432, 0.41960788],\n         [0.31764707, 0.3529412 , 0.41176474],\n         [0.3019608 , 0.3372549 , 0.39607847],\n         ...,\n         [0.0627451 , 0.14117648, 0.24705884],\n         [0.07450981, 0.16862746, 0.27058825],\n         [0.09411766, 0.18823531, 0.2901961 ]],\n\n        [[0.29803923, 0.33333334, 0.3921569 ],\n         [0.2901961 , 0.3254902 , 0.38431376],\n         [0.2784314 , 0.3137255 , 0.37254903],\n         ...,\n         [0.04705883, 0.12941177, 0.23529413],\n         [0.04705883, 0.14117648, 0.24313727],\n         [0.04705883, 0.14117648, 0.24313727]]],\n\n\n       [[[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        [[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        [[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        ...,\n\n        [[0.2392157 , 0.1764706 , 0.1764706 ],\n         [0.20392159, 0.14901961, 0.13725491],\n         [0.22352943, 0.18823531, 0.16078432],\n         ...,\n         [0.14117648, 0.16078432, 0.08235294],\n         [0.15686275, 0.1764706 , 0.09019608],\n         [0.14117648, 0.16078432, 0.07450981]],\n\n        [[0.16078432, 0.08627451, 0.10980393],\n         [0.0627451 , 0.        , 0.01960784],\n         [0.08235294, 0.02745098, 0.02745098],\n         ...,\n         [0.07843138, 0.09019608, 0.04705883],\n         [0.07058824, 0.08627451, 0.03137255],\n         [0.07843138, 0.09411766, 0.03921569]],\n\n        [[0.10588236, 0.02745098, 0.07058824],\n         [0.10196079, 0.02352941, 0.06666667],\n         [0.11764707, 0.05882353, 0.07843138],\n         ...,\n         [0.09803922, 0.10196079, 0.08235294],\n         [0.01176471, 0.01568628, 0.        ],\n         [0.03921569, 0.04313726, 0.01960784]]],\n\n\n       ...,\n\n\n       [[[0.38823533, 0.39607847, 0.4784314 ],\n         [0.5176471 , 0.5254902 , 0.60784316],\n         [0.8235295 , 0.8313726 , 0.91372555],\n         ...,\n         [0.8941177 , 0.8980393 , 0.91372555],\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ]],\n\n        [[0.7568628 , 0.7686275 , 0.8431373 ],\n         [0.6392157 , 0.6509804 , 0.7254902 ],\n         [0.7686275 , 0.7803922 , 0.854902  ],\n         ...,\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ]],\n\n        [[0.36862746, 0.3803922 , 0.43921572],\n         [0.6627451 , 0.6745098 , 0.73333335],\n         [0.97647065, 0.98823535, 1.        ],\n         ...,\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.8862746 , 0.89019614, 0.9058824 ],\n         [0.8862746 , 0.89019614, 0.9058824 ]],\n\n        ...,\n\n        [[0.7019608 , 0.68235296, 0.69803923],\n         [0.73333335, 0.7137255 , 0.7294118 ],\n         [0.7294118 , 0.70980394, 0.7254902 ],\n         ...,\n         [0.8313726 , 0.8078432 , 0.8235295 ],\n         [0.8313726 , 0.8078432 , 0.8235295 ],\n         [0.82745105, 0.80392164, 0.8196079 ]],\n\n        [[0.42352945, 0.4039216 , 0.41960788],\n         [0.6313726 , 0.6117647 , 0.627451  ],\n         [0.77647066, 0.7568628 , 0.7725491 ],\n         ...,\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.82745105, 0.80392164, 0.8196079 ]],\n\n        [[0.7607844 , 0.7411765 , 0.7568628 ],\n         [0.74509805, 0.7254902 , 0.7411765 ],\n         [0.7058824 , 0.6862745 , 0.7019608 ],\n         ...,\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.82745105, 0.80392164, 0.8196079 ],\n         [0.8313726 , 0.8078432 , 0.8235295 ]]],\n\n\n       [[[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8235295 , 0.8235295 , 0.8235295 ],\n         [0.85098046, 0.85098046, 0.8588236 ],\n         [0.8705883 , 0.8705883 , 0.87843144]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8313726 , 0.8313726 , 0.8313726 ],\n         [0.854902  , 0.854902  , 0.86274517],\n         [0.87843144, 0.87843144, 0.8862746 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8352942 , 0.8352942 , 0.8352942 ],\n         [0.854902  , 0.854902  , 0.86274517],\n         [0.87843144, 0.87843144, 0.8862746 ]],\n\n        ...,\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.5686275 , 0.5686275 , 0.5764706 ],\n         ...,\n         [0.2392157 , 0.06666667, 0.0627451 ],\n         [0.25490198, 0.11764707, 0.10196079],\n         [0.6862745 , 0.5686275 , 0.5372549 ]],\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.5686275 , 0.5686275 , 0.5764706 ],\n         ...,\n         [0.50980395, 0.32941177, 0.32941177],\n         [0.16470589, 0.03529412, 0.00784314],\n         [0.79215693, 0.6862745 , 0.6509804 ]],\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.56078434, 0.5647059 , 0.5803922 ],\n         ...,\n         [0.5294118 , 0.3529412 , 0.34117648],\n         [0.45098042, 0.32156864, 0.29411766],\n         [0.3254902 , 0.23137257, 0.19215688]]],\n\n\n       [[[1.        , 0.98823535, 0.9803922 ],\n         [1.        , 0.98823535, 0.9803922 ],\n         [1.        , 0.98823535, 0.9803922 ],\n         ...,\n         [0.9725491 , 1.        , 0.9803922 ],\n         [0.9725491 , 1.        , 0.9960785 ],\n         [0.9725491 , 1.        , 1.        ]],\n\n        [[1.        , 0.98823535, 0.9843138 ],\n         [1.        , 0.98823535, 0.9843138 ],\n         [1.        , 0.9921569 , 0.9843138 ],\n         ...,\n         [1.        , 0.9921569 , 0.9921569 ],\n         [1.        , 0.98823535, 0.9960785 ],\n         [1.        , 0.9843138 , 1.        ]],\n\n        [[1.        , 0.98823535, 1.        ],\n         [1.        , 0.9921569 , 1.        ],\n         [1.        , 0.9921569 , 1.        ],\n         ...,\n         [1.        , 0.9686275 , 1.        ],\n         [1.        , 0.96470594, 1.        ],\n         [1.        , 0.9607844 , 1.        ]],\n\n        ...,\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]]]], dtype=float32)}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 124\u001b[0m\n\u001b[0;32m    121\u001b[0m         text_batch \u001b[38;5;241m=\u001b[39m text_data[start_idx:start_idx \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: text_batch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_input\u001b[39m\u001b[38;5;124m\"\u001b[39m: image_batch}\n\u001b[1;32m--> 124\u001b[0m y_pred_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(predict_generator(X_test_text, val_generator), steps\u001b[38;5;241m=\u001b[39mvalidation_steps)\n\u001b[0;32m    125\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m (y_pred_probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Align y_test\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\generator_data_adapter.py:17\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[1;34m(self, generator)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_batches[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen passing a Python generator to a Keras model, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe generator must return a tuple, either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(input,) or (inputs, targets) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(inputs, targets, sample_weights). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirst_batches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: When passing a Python generator to a Keras model, the generator must return a tuple, either (input,) or (inputs, targets) or (inputs, targets, sample_weights). Received: {'text_input': array([[   0,    0,    0, ..., 6226,    2,   91],\n       [   0,    0,    0, ..., 4129,   31, 1280],\n       [   0,    0,    0, ..., 2337,  362,   22],\n       ...,\n       [   0,    0,    0, ..., 2058, 1142,  312],\n       [   0,    0,    0, ..., 1936,    6,   42],\n       [   0,    0,    0, ...,    2,    1, 3687]]), 'image_input': array([[[[0.7176471 , 0.6509804 , 0.72156864],\n         [0.7176471 , 0.6509804 , 0.72156864],\n         [0.7176471 , 0.6509804 , 0.7137255 ],\n         ...,\n         [0.4039216 , 0.20784315, 0.07843138],\n         [0.3921569 , 0.19607845, 0.06666667],\n         [0.37647063, 0.1764706 , 0.05490196]],\n\n        [[0.69803923, 0.6313726 , 0.7019608 ],\n         [0.7019608 , 0.63529414, 0.7058824 ],\n         [0.7019608 , 0.63529414, 0.69803923],\n         ...,\n         [0.4039216 , 0.20784315, 0.07843138],\n         [0.4156863 , 0.21960786, 0.09019608],\n         [0.35686275, 0.15686275, 0.03529412]],\n\n        [[0.67058825, 0.6156863 , 0.68235296],\n         [0.6745098 , 0.61960787, 0.6862745 ],\n         [0.6784314 , 0.62352943, 0.68235296],\n         ...,\n         [0.3921569 , 0.19607845, 0.06666667],\n         [0.43529415, 0.2392157 , 0.10980393],\n         [0.31764707, 0.11764707, 0.        ]],\n\n        ...,\n\n        [[0.07843138, 0.09019608, 0.10980393],\n         [0.13725491, 0.14901961, 0.16862746],\n         [0.20392159, 0.20784315, 0.227451  ],\n         ...,\n         [0.19607845, 0.05882353, 0.0509804 ],\n         [0.12941177, 0.00392157, 0.01568628],\n         [0.15294118, 0.03137255, 0.05490196]],\n\n        [[0.1137255 , 0.12941177, 0.14117648],\n         [0.16470589, 0.18039216, 0.19215688],\n         [0.21960786, 0.23137257, 0.2509804 ],\n         ...,\n         [0.20000002, 0.0627451 , 0.05490196],\n         [0.1254902 , 0.        , 0.01176471],\n         [0.16470589, 0.04313726, 0.0627451 ]],\n\n        [[0.15294118, 0.17254902, 0.18431373],\n         [0.20392159, 0.21960786, 0.23137257],\n         [0.24313727, 0.25882354, 0.27058825],\n         ...,\n         [0.20784315, 0.07058824, 0.0627451 ],\n         [0.1254902 , 0.        , 0.00392157],\n         [0.1764706 , 0.05490196, 0.07450981]]],\n\n\n       [[[0.5882353 , 0.59607846, 0.64705884],\n         [0.57254905, 0.58431375, 0.6431373 ],\n         [0.5411765 , 0.5647059 , 0.627451  ],\n         ...,\n         [0.61960787, 0.63529414, 0.68235296],\n         [0.7019608 , 0.7176471 , 0.76470596],\n         [0.6862745 , 0.7019608 , 0.7490196 ]],\n\n        [[0.5686275 , 0.5803922 , 0.6392157 ],\n         [0.56078434, 0.57254905, 0.6313726 ],\n         [0.5372549 , 0.56078434, 0.62352943],\n         ...,\n         [0.7019608 , 0.70980394, 0.7568628 ],\n         [0.72156864, 0.7372549 , 0.7803922 ],\n         [0.6627451 , 0.6784314 , 0.72156864]],\n\n        [[0.57254905, 0.58431375, 0.6431373 ],\n         [0.5764706 , 0.5882353 , 0.64705884],\n         [0.56078434, 0.58431375, 0.64705884],\n         ...,\n         [0.64705884, 0.65882355, 0.6862745 ],\n         [0.7254902 , 0.7372549 , 0.76470596],\n         [0.7254902 , 0.74509805, 0.7686275 ]],\n\n        ...,\n\n        [[0.36078432, 0.39607847, 0.454902  ],\n         [0.34901962, 0.38431376, 0.4431373 ],\n         [0.33333334, 0.36862746, 0.427451  ],\n         ...,\n         [0.07843138, 0.15686275, 0.2627451 ],\n         [0.10588236, 0.18823531, 0.29411766],\n         [0.13333334, 0.227451  , 0.32941177]],\n\n        [[0.3254902 , 0.36078432, 0.41960788],\n         [0.31764707, 0.3529412 , 0.41176474],\n         [0.3019608 , 0.3372549 , 0.39607847],\n         ...,\n         [0.0627451 , 0.14117648, 0.24705884],\n         [0.07450981, 0.16862746, 0.27058825],\n         [0.09411766, 0.18823531, 0.2901961 ]],\n\n        [[0.29803923, 0.33333334, 0.3921569 ],\n         [0.2901961 , 0.3254902 , 0.38431376],\n         [0.2784314 , 0.3137255 , 0.37254903],\n         ...,\n         [0.04705883, 0.12941177, 0.23529413],\n         [0.04705883, 0.14117648, 0.24313727],\n         [0.04705883, 0.14117648, 0.24313727]]],\n\n\n       [[[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        [[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        [[0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         ...,\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ],\n         [0.09411766, 0.04705883, 0.0627451 ]],\n\n        ...,\n\n        [[0.2392157 , 0.1764706 , 0.1764706 ],\n         [0.20392159, 0.14901961, 0.13725491],\n         [0.22352943, 0.18823531, 0.16078432],\n         ...,\n         [0.14117648, 0.16078432, 0.08235294],\n         [0.15686275, 0.1764706 , 0.09019608],\n         [0.14117648, 0.16078432, 0.07450981]],\n\n        [[0.16078432, 0.08627451, 0.10980393],\n         [0.0627451 , 0.        , 0.01960784],\n         [0.08235294, 0.02745098, 0.02745098],\n         ...,\n         [0.07843138, 0.09019608, 0.04705883],\n         [0.07058824, 0.08627451, 0.03137255],\n         [0.07843138, 0.09411766, 0.03921569]],\n\n        [[0.10588236, 0.02745098, 0.07058824],\n         [0.10196079, 0.02352941, 0.06666667],\n         [0.11764707, 0.05882353, 0.07843138],\n         ...,\n         [0.09803922, 0.10196079, 0.08235294],\n         [0.01176471, 0.01568628, 0.        ],\n         [0.03921569, 0.04313726, 0.01960784]]],\n\n\n       ...,\n\n\n       [[[0.38823533, 0.39607847, 0.4784314 ],\n         [0.5176471 , 0.5254902 , 0.60784316],\n         [0.8235295 , 0.8313726 , 0.91372555],\n         ...,\n         [0.8941177 , 0.8980393 , 0.91372555],\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ]],\n\n        [[0.7568628 , 0.7686275 , 0.8431373 ],\n         [0.6392157 , 0.6509804 , 0.7254902 ],\n         [0.7686275 , 0.7803922 , 0.854902  ],\n         ...,\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.89019614, 0.8941177 , 0.909804  ]],\n\n        [[0.36862746, 0.3803922 , 0.43921572],\n         [0.6627451 , 0.6745098 , 0.73333335],\n         [0.97647065, 0.98823535, 1.        ],\n         ...,\n         [0.89019614, 0.8941177 , 0.909804  ],\n         [0.8862746 , 0.89019614, 0.9058824 ],\n         [0.8862746 , 0.89019614, 0.9058824 ]],\n\n        ...,\n\n        [[0.7019608 , 0.68235296, 0.69803923],\n         [0.73333335, 0.7137255 , 0.7294118 ],\n         [0.7294118 , 0.70980394, 0.7254902 ],\n         ...,\n         [0.8313726 , 0.8078432 , 0.8235295 ],\n         [0.8313726 , 0.8078432 , 0.8235295 ],\n         [0.82745105, 0.80392164, 0.8196079 ]],\n\n        [[0.42352945, 0.4039216 , 0.41960788],\n         [0.6313726 , 0.6117647 , 0.627451  ],\n         [0.77647066, 0.7568628 , 0.7725491 ],\n         ...,\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.82745105, 0.80392164, 0.8196079 ]],\n\n        [[0.7607844 , 0.7411765 , 0.7568628 ],\n         [0.74509805, 0.7254902 , 0.7411765 ],\n         [0.7058824 , 0.6862745 , 0.7019608 ],\n         ...,\n         [0.8235295 , 0.8000001 , 0.81568635],\n         [0.82745105, 0.80392164, 0.8196079 ],\n         [0.8313726 , 0.8078432 , 0.8235295 ]]],\n\n\n       [[[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8235295 , 0.8235295 , 0.8235295 ],\n         [0.85098046, 0.85098046, 0.8588236 ],\n         [0.8705883 , 0.8705883 , 0.87843144]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8313726 , 0.8313726 , 0.8313726 ],\n         [0.854902  , 0.854902  , 0.86274517],\n         [0.87843144, 0.87843144, 0.8862746 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [0.8352942 , 0.8352942 , 0.8352942 ],\n         [0.854902  , 0.854902  , 0.86274517],\n         [0.87843144, 0.87843144, 0.8862746 ]],\n\n        ...,\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.5686275 , 0.5686275 , 0.5764706 ],\n         ...,\n         [0.2392157 , 0.06666667, 0.0627451 ],\n         [0.25490198, 0.11764707, 0.10196079],\n         [0.6862745 , 0.5686275 , 0.5372549 ]],\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.5686275 , 0.5686275 , 0.5764706 ],\n         ...,\n         [0.50980395, 0.32941177, 0.32941177],\n         [0.16470589, 0.03529412, 0.00784314],\n         [0.79215693, 0.6862745 , 0.6509804 ]],\n\n        [[0.5764706 , 0.5764706 , 0.58431375],\n         [0.57254905, 0.57254905, 0.5803922 ],\n         [0.56078434, 0.5647059 , 0.5803922 ],\n         ...,\n         [0.5294118 , 0.3529412 , 0.34117648],\n         [0.45098042, 0.32156864, 0.29411766],\n         [0.3254902 , 0.23137257, 0.19215688]]],\n\n\n       [[[1.        , 0.98823535, 0.9803922 ],\n         [1.        , 0.98823535, 0.9803922 ],\n         [1.        , 0.98823535, 0.9803922 ],\n         ...,\n         [0.9725491 , 1.        , 0.9803922 ],\n         [0.9725491 , 1.        , 0.9960785 ],\n         [0.9725491 , 1.        , 1.        ]],\n\n        [[1.        , 0.98823535, 0.9843138 ],\n         [1.        , 0.98823535, 0.9843138 ],\n         [1.        , 0.9921569 , 0.9843138 ],\n         ...,\n         [1.        , 0.9921569 , 0.9921569 ],\n         [1.        , 0.98823535, 0.9960785 ],\n         [1.        , 0.9843138 , 1.        ]],\n\n        [[1.        , 0.98823535, 1.        ],\n         [1.        , 0.9921569 , 1.        ],\n         [1.        , 0.9921569 , 1.        ],\n         ...,\n         [1.        , 0.9686275 , 1.        ],\n         [1.        , 0.96470594, 1.        ],\n         [1.        , 0.9607844 , 1.        ]],\n\n        ...,\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]],\n\n        [[1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         ...,\n         [1.        , 1.        , 1.        ],\n         [1.        , 1.        , 1.        ],\n         [0.9960785 , 0.9960785 , 0.9960785 ]]]], dtype=float32)}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Concatenate\n",
    ")\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Load and Preprocess Text Data ---\n",
    "file_path = r\"F:\\\\irmatext\\\\Hurricane_irma.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "data['processed_data'] = data['processed_data'].fillna('').astype(str)\n",
    "data['Binary_Class'] = data['Binary_Class'].map({'Non-Damage': 0, 'Damage': 1})\n",
    "\n",
    "sentences = [sentence.split() for sentence in data['processed_data']]\n",
    "labels = data['Binary_Class'].values\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Word2Vec\n",
    "word2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1)\n",
    "vocab_size = len(word2vec_model.wv)\n",
    "embedding_dim = word2vec_model.vector_size\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))\n",
    "word_index = {word: idx + 1 for idx, word in enumerate(word2vec_model.wv.index_to_key)}\n",
    "for word, idx in word_index.items():\n",
    "    embedding_matrix[idx] = word2vec_model.wv[word]\n",
    "\n",
    "# Convert text data to padded sequences\n",
    "X_train_text = [[word_index.get(word, 0) for word in sentence] for sentence in X_train_text]\n",
    "X_test_text = [[word_index.get(word, 0) for word in sentence] for sentence in X_test_text]\n",
    "X_train_text = pad_sequences(X_train_text, maxlen=100)\n",
    "X_test_text = pad_sequences(X_test_text, maxlen=100)\n",
    "\n",
    "# --- Preprocess Image Data ---\n",
    "train_data_dir = r\"F:\\\\data_image\\\\preprocessed_images\\\\train\"\n",
    "val_data_dir = r\"F:\\\\data_image\\\\preprocessed_images\\\\validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, target_size=(224, 224), batch_size=16, class_mode='binary'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir, target_size=(224, 224), batch_size=16, class_mode='binary'\n",
    ")\n",
    "\n",
    "# --- Build Text Model ---\n",
    "text_input = Input(shape=(100,), name=\"text_input\")\n",
    "text_embedding = Embedding(input_dim=vocab_size + 1, output_dim=embedding_dim, weights=[embedding_matrix],\n",
    "                           input_length=100, trainable=True)(text_input)\n",
    "text_cnn = Conv1D(filters=128, kernel_size=3, activation='relu')(text_embedding)\n",
    "text_cnn = MaxPooling1D(pool_size=2)(text_cnn)\n",
    "text_cnn = Flatten()(text_cnn)\n",
    "text_output = Dense(128, activation='relu')(text_cnn)\n",
    "\n",
    "# --- Build Image Model ---\n",
    "image_input = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "for layer in base_model.layers[:-4]:  # Unfreeze last 4 layers\n",
    "    layer.trainable = False\n",
    "image_cnn = Flatten()(base_model.output)\n",
    "image_output = Dense(256, activation='relu')(image_cnn)\n",
    "\n",
    "# --- Merge Models ---\n",
    "merged = Concatenate()([text_output, image_output])\n",
    "merged_dense = Dense(128, activation='relu')(merged)\n",
    "merged_output = Dense(1, activation='sigmoid', name=\"output\")(merged_dense)\n",
    "\n",
    "model = Model(inputs=[text_input, image_input], outputs=merged_output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# --- Define Data Generator ---\n",
    "def data_generator(text_data, image_generator, labels):\n",
    "    while True:\n",
    "        image_batch, _ = next(image_generator)  # Get images and ignore labels from the generator\n",
    "        batch_size = len(image_batch)\n",
    "        start_idx = np.random.randint(0, len(text_data) - batch_size + 1)\n",
    "        text_batch = text_data[start_idx:start_idx + batch_size]\n",
    "        label_batch = labels[start_idx:start_idx + batch_size]\n",
    "        yield {\"text_input\": text_batch, \"image_input\": image_batch}, label_batch\n",
    "\n",
    "train_gen = data_generator(X_train_text, train_generator, y_train)\n",
    "val_gen = data_generator(X_test_text, val_generator, y_test)\n",
    "\n",
    "steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(val_generator)\n",
    "\n",
    "# --- Train Model ---\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# --- Predict with Validation Generator ---\n",
    "def predict_generator(text_data, image_generator):\n",
    "    for _ in range(len(image_generator)):\n",
    "        image_batch, _ = next(image_generator)\n",
    "        batch_size = len(image_batch)\n",
    "        start_idx = np.random.randint(0, len(text_data) - batch_size + 1)\n",
    "        text_batch = text_data[start_idx:start_idx + batch_size]\n",
    "        yield {\"text_input\": text_batch, \"image_input\": image_batch}\n",
    "\n",
    "y_pred_probs = model.predict(predict_generator(X_test_text, val_generator), steps=validation_steps)\n",
    "y_pred_classes = (y_pred_probs > 0.5).astype(\"int32\")\n",
    "\n",
    "# Align y_test\n",
    "y_test_eval = y_test[:validation_steps * train_generator.batch_size]\n",
    "\n",
    "# --- Evaluate Model ---\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_eval, y_pred_classes):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_eval, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ece3f-5e42-4ee1-b011-ebd12f97b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

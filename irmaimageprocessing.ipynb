{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "995ff54d-506a-4067-b579-6387581eed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for training.\n",
      "Folder structure aligned. Missing folders added where necessary.\n",
      "Found 4379 images belonging to 8 classes.\n",
      "Found 1713 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3286s\u001b[0m 12s/step - accuracy: 0.2554 - loss: 2.1362 - val_accuracy: 0.3339 - val_loss: 1.5078 - learning_rate: 1.0000e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3270s\u001b[0m 12s/step - accuracy: 0.3029 - loss: 1.6302 - val_accuracy: 0.3304 - val_loss: 1.4355 - learning_rate: 1.0000e-06\n",
      "Epoch 3/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3262s\u001b[0m 12s/step - accuracy: 0.3256 - loss: 1.5605 - val_accuracy: 0.3368 - val_loss: 1.4109 - learning_rate: 1.0000e-06\n",
      "Epoch 4/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3271s\u001b[0m 12s/step - accuracy: 0.3259 - loss: 1.5084 - val_accuracy: 0.3398 - val_loss: 1.3949 - learning_rate: 1.0000e-06\n",
      "Epoch 5/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3277s\u001b[0m 12s/step - accuracy: 0.3272 - loss: 1.4901 - val_accuracy: 0.3438 - val_loss: 1.3851 - learning_rate: 1.0000e-06\n",
      "Epoch 6/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3271s\u001b[0m 12s/step - accuracy: 0.3319 - loss: 1.4824 - val_accuracy: 0.3503 - val_loss: 1.3751 - learning_rate: 1.0000e-06\n",
      "Epoch 7/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3270s\u001b[0m 12s/step - accuracy: 0.3276 - loss: 1.4659 - val_accuracy: 0.3573 - val_loss: 1.3687 - learning_rate: 1.0000e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3265s\u001b[0m 12s/step - accuracy: 0.3225 - loss: 1.4483 - val_accuracy: 0.3619 - val_loss: 1.3629 - learning_rate: 1.0000e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3268s\u001b[0m 12s/step - accuracy: 0.3384 - loss: 1.4262 - val_accuracy: 0.3573 - val_loss: 1.3583 - learning_rate: 1.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3320s\u001b[0m 12s/step - accuracy: 0.3450 - loss: 1.4173 - val_accuracy: 0.3602 - val_loss: 1.3541 - learning_rate: 1.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3272s\u001b[0m 12s/step - accuracy: 0.3248 - loss: 1.4263 - val_accuracy: 0.3614 - val_loss: 1.3505 - learning_rate: 1.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3269s\u001b[0m 12s/step - accuracy: 0.3455 - loss: 1.4168 - val_accuracy: 0.3631 - val_loss: 1.3462 - learning_rate: 1.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3266s\u001b[0m 12s/step - accuracy: 0.3442 - loss: 1.4046 - val_accuracy: 0.3719 - val_loss: 1.3424 - learning_rate: 1.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3272s\u001b[0m 12s/step - accuracy: 0.3544 - loss: 1.4006 - val_accuracy: 0.3614 - val_loss: 1.3402 - learning_rate: 1.0000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3267s\u001b[0m 12s/step - accuracy: 0.3594 - loss: 1.3881 - val_accuracy: 0.3689 - val_loss: 1.3358 - learning_rate: 1.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3265s\u001b[0m 12s/step - accuracy: 0.3503 - loss: 1.3769 - val_accuracy: 0.3684 - val_loss: 1.3330 - learning_rate: 1.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3269s\u001b[0m 12s/step - accuracy: 0.3660 - loss: 1.3799 - val_accuracy: 0.3707 - val_loss: 1.3297 - learning_rate: 1.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3267s\u001b[0m 12s/step - accuracy: 0.3708 - loss: 1.3773 - val_accuracy: 0.3730 - val_loss: 1.3258 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3269s\u001b[0m 12s/step - accuracy: 0.3470 - loss: 1.3766 - val_accuracy: 0.3759 - val_loss: 1.3233 - learning_rate: 1.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3264s\u001b[0m 12s/step - accuracy: 0.3557 - loss: 1.3664 - val_accuracy: 0.3894 - val_loss: 1.3205 - learning_rate: 1.0000e-06\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m910s\u001b[0m 8s/step\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.3211\n",
      "Precision: 0.2632\n",
      "Recall: 0.3211\n",
      "F1 Score: 0.2615\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.17      0.02      0.03       339\n",
      "           2       0.35      0.64      0.45       607\n",
      "           3       0.29      0.28      0.29       536\n",
      "           4       0.12      0.03      0.05       212\n",
      "\n",
      "    accuracy                           0.32      1713\n",
      "   macro avg       0.19      0.19      0.16      1713\n",
      "weighted avg       0.26      0.32      0.26      1713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Force TensorFlow to use CPU\n",
    "tf.config.set_visible_devices([], 'GPU')  # Disables GPU\n",
    "print(\"Using CPU for training.\")\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Update the output layer to match the number of classes\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(8, activation='softmax')(x)  # Update this to the correct number of classes\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=1e-6)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Image data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True, rotation_range=20)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Define the directory path for train and validation sets\n",
    "train_data_dir = r\"F:\\data_image\\preprocessed_images\"\n",
    "\n",
    "# Paths for train and validation folders\n",
    "train_dir = os.path.join(train_data_dir, \"train\")\n",
    "val_dir = os.path.join(train_data_dir, \"validation\")\n",
    "\n",
    "# Ensure the directories exist, create them if missing\n",
    "if not os.path.exists(train_dir):\n",
    "    print(f\"Creating missing directory: {train_dir}\")\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "if not os.path.exists(val_dir):\n",
    "    print(f\"Creating missing directory: {val_dir}\")\n",
    "    os.makedirs(val_dir)\n",
    "\n",
    "# Check for class consistency\n",
    "train_classes = set(os.listdir(train_dir))\n",
    "val_classes = set(os.listdir(val_dir))\n",
    "\n",
    "# Identify mismatched classes\n",
    "missing_in_val = train_classes - val_classes\n",
    "missing_in_train = val_classes - train_classes\n",
    "\n",
    "# Fix folder structure by creating missing class directories\n",
    "for class_name in missing_in_val:\n",
    "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "for class_name in missing_in_train:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "\n",
    "print(\"Folder structure aligned. Missing folders added where necessary.\")\n",
    "\n",
    "# Prepare the data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Verify class indices are consistent\n",
    "if train_generator.class_indices != val_generator.class_indices:\n",
    "    raise ValueError(\"Class indices in train and validation sets are inconsistent. Check folder structure.\")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_generator.reset()\n",
    "y_true = val_generator.classes\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = tf.argmax(y_pred, axis=1).numpy()\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef328c17-9fd9-449e-a8f2-769c89cb6901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

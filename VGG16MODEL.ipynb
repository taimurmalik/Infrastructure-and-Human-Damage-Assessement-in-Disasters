{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bsMMbVFPHZE",
        "outputId": "5b228c41-decf-4eb3-c777-d4ac8ae43207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU for training.\n",
            "Found 3505 images belonging to 5 classes.\n",
            "Found 874 images belonging to 5 classes.\n",
            "Found 1735 images belonging to 5 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1324s\u001b[0m 6s/step - accuracy: 0.2182 - loss: 1.9892 - val_accuracy: 0.3169 - val_loss: 1.4735 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 296ms/step - accuracy: 0.2372 - loss: 1.6623 - val_accuracy: 0.1808 - val_loss: 1.5992 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 289ms/step - accuracy: 0.2047 - loss: 1.5200 - val_accuracy: 0.1396 - val_loss: 1.6609 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 289ms/step - accuracy: 0.1128 - loss: 1.6591 - val_accuracy: 0.2002 - val_loss: 1.5337 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 291ms/step - accuracy: 0.1959 - loss: 1.5674 - val_accuracy: 0.2414 - val_loss: 1.5452 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 292ms/step - accuracy: 0.1994 - loss: 1.4510 - val_accuracy: 0.1636 - val_loss: 1.5958 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 297ms/step - accuracy: 0.1945 - loss: 1.5770 - val_accuracy: 0.2838 - val_loss: 1.5103 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 296ms/step - accuracy: 0.2130 - loss: 1.5190 - val_accuracy: 0.2254 - val_loss: 1.5279 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 291ms/step - accuracy: 0.2238 - loss: 1.5271 - val_accuracy: 0.2254 - val_loss: 1.5314 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 299ms/step - accuracy: 0.2183 - loss: 1.4718 - val_accuracy: 0.2483 - val_loss: 1.5173 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.2347 - loss: 1.5106\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 291ms/step - accuracy: 0.2347 - loss: 1.5106 - val_accuracy: 0.2071 - val_loss: 1.5871 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 292ms/step - accuracy: 0.1992 - loss: 1.4917 - val_accuracy: 0.3021 - val_loss: 1.5059 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 292ms/step - accuracy: 0.2577 - loss: 1.4829 - val_accuracy: 0.2906 - val_loss: 1.5106 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 298ms/step - accuracy: 0.2455 - loss: 1.5245 - val_accuracy: 0.2838 - val_loss: 1.5087 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 296ms/step - accuracy: 0.2398 - loss: 1.4866 - val_accuracy: 0.2963 - val_loss: 1.4994 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 298ms/step - accuracy: 0.2625 - loss: 1.4273 - val_accuracy: 0.2666 - val_loss: 1.5295 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 291ms/step - accuracy: 0.2333 - loss: 1.4714 - val_accuracy: 0.2586 - val_loss: 1.5322 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 299ms/step - accuracy: 0.2285 - loss: 1.4545 - val_accuracy: 0.2677 - val_loss: 1.5226 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 296ms/step - accuracy: 0.2482 - loss: 1.5417 - val_accuracy: 0.2689 - val_loss: 1.5112 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 292ms/step - accuracy: 0.2488 - loss: 1.4329 - val_accuracy: 0.2529 - val_loss: 1.5287 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.2442 - loss: 1.4592\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 293ms/step - accuracy: 0.2442 - loss: 1.4592 - val_accuracy: 0.2689 - val_loss: 1.5275 - learning_rate: 1.0000e-05\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 5s/step\n",
            "Evaluation Metrics:\n",
            "Accuracy: 0.3429\n",
            "Precision: 0.3722\n",
            "Recall: 0.3429\n",
            "F1 Score: 0.3143\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.30      0.09        20\n",
            "           1       0.43      0.01      0.02       343\n",
            "           2       0.40      0.47      0.43       609\n",
            "           3       0.35      0.43      0.38       546\n",
            "           4       0.31      0.31      0.31       217\n",
            "\n",
            "    accuracy                           0.34      1735\n",
            "   macro avg       0.31      0.30      0.25      1735\n",
            "weighted avg       0.37      0.34      0.31      1735\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Force TensorFlow to use GPU if available\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
        "    print(\"Using GPU for training.\")\n",
        "else:\n",
        "    print(\"Using CPU for training.\")\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Fine-tune the deeper layers of the base model\n",
        "for layer in base_model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Dynamically update the output layer to match the number of classes\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(8, activation='softmax')(x)  # Update this to the correct number of classes\n",
        "\n",
        "# Create and compile the final model\n",
        "model = Model(inputs=base_model.input, outputs=output_layer)\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Image data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Define the directory path for train and validation sets\n",
        "train_data_dir = r\"F:\\data_image\\preprocessed_images\"\n",
        "\n",
        "# Paths for train and validation folders\n",
        "train_dir = os.path.join(train_data_dir, \"train\")\n",
        "val_dir = os.path.join(train_data_dir, \"validation\")\n",
        "\n",
        "# Ensure the directories exist, create them if missing\n",
        "if not os.path.exists(train_dir):\n",
        "    print(f\"Creating missing directory: {train_dir}\")\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    print(f\"Creating missing directory: {val_dir}\")\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "# Check for class consistency\n",
        "train_classes = set(os.listdir(train_dir))\n",
        "val_classes = set(os.listdir(val_dir))\n",
        "\n",
        "# Identify mismatched classes\n",
        "missing_in_val = train_classes - val_classes\n",
        "missing_in_train = val_classes - train_classes\n",
        "\n",
        "# Fix folder structure by creating missing class directories\n",
        "for class_name in missing_in_val:\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "for class_name in missing_in_train:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "\n",
        "print(\"Folder structure aligned. Missing folders added where necessary.\")\n",
        "\n",
        "# Prepare the data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "print(\"Class weights computed:\", class_weights)\n",
        "\n",
        "# Callbacks for improved training performance\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "val_generator.reset()\n",
        "y_true = val_generator.classes\n",
        "y_pred = model.predict(val_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uZ6foK_c2tcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}